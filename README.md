# Project GenAI : Assistant de RÃ©ponses sur le Basketball ğŸ€

## Description du Projet

Ce projet est un systÃ¨me de Question-RÃ©ponse spÃ©cialisÃ© dans le domaine du basketball. Il utilise des techniques avancÃ©es de NLP (Natural Language Processing) et de RAG (Retrieval Augmented Generation) pour fournir des rÃ©ponses prÃ©cises et pertinentes Ã  des questions sur le basketball en se basant sur des donnÃ©es extraites de WikipÃ©dia.

## FonctionnalitÃ©s

- **Recherche SÃ©mantique** : Utilisation d'embeddings vectoriels pour trouver les passages les plus pertinents en fonction d'une question.
- **Extraction de Contexte** : RÃ©cupÃ©ration des textes les plus similaires Ã  la requÃªte de l'utilisateur.
- **GÃ©nÃ©ration de RÃ©ponses** : Utilisation du modÃ¨le Mistral via Ollama pour gÃ©nÃ©rer des rÃ©ponses basÃ©es sur le contexte extrait.
- **Interface Web** : Interface utilisateur simple crÃ©Ã©e avec Streamlit permettant de poser des questions et d'obtenir des rÃ©ponses.

## Architecture du Projet

Le projet est organisÃ© selon la structure suivante :

```
Project_genai/
â”œâ”€â”€ app.py                  # Application Streamlit principale
â”œâ”€â”€ requirements.txt        # DÃ©pendances du projet
â”œâ”€â”€ data/                   # DonnÃ©es utilisÃ©es par l'application
â”‚   â””â”€â”€ wikipedia_basketball_articles.csv  # DonnÃ©es extraites de WikipÃ©dia
â””â”€â”€ modules/                # Modules et composants du systÃ¨me
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data_loader.py      # Chargement et prÃ©traitement des donnÃ©es
    â”œâ”€â”€ faiss_indexeur.py   # Gestion de l'index FAISS pour la recherche vectorielle
    â”œâ”€â”€ generator.py        # GÃ©nÃ©ration de rÃ©ponses avec le modÃ¨le Mistral (Ollama)
    â”œâ”€â”€ retriever.py        # RÃ©cupÃ©ration des passages pertinents
    â”œâ”€â”€ scrapping.py        # Extraction des donnÃ©es depuis WikipÃ©dia
    â””â”€â”€ vectore_store.py    # Manipulation des vecteurs et embeddings
```

## PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Ollama installÃ© localement avec le modÃ¨le Mistral
- DÃ©pendances Python listÃ©es dans `requirements.txt`

## Installation

1. Clonez le dÃ©pÃ´t :
```
git clone https://github.com/Hous20/Project_genai.git
cd Project_genai
```

2. Installez les dÃ©pendances :
```
pip install -r requirements.txt
```

3. Assurez-vous que Ollama est installÃ© et que le modÃ¨le Mistral est disponible :
```
ollama pull mistral
```

## Utilisation

1. Pour collecter des donnÃ©es de WikipÃ©dia (dÃ©jÃ  disponibles dans le rÃ©pertoire `data/`) :
```
python -m modules.scrapping
```

2. Pour crÃ©er l'index FAISS Ã  partir des articles (Ã  faire une seule fois) :
```
# CrÃ©ez un script build_index.py avec le code appropriÃ© utilisant les fonctions de faiss_indexeur.py
```

3. Pour lancer l'application :
```
streamlit run app.py
```

4. Visitez l'URL locale indiquÃ©e (gÃ©nÃ©ralement http://localhost:8501) et posez vos questions sur le basketball.

## Fonctionnement

1. L'utilisateur pose une question via l'interface Streamlit.
2. Le systÃ¨me convertit la question en vecteur d'embeddings Ã  l'aide du modÃ¨le SentenceTransformer.
3. L'index FAISS est utilisÃ© pour trouver les passages les plus similaires Ã  la question.
4. Ces passages sont compilÃ©s pour former un contexte pertinent.
5. Le modÃ¨le Mistral (via Ollama) gÃ©nÃ¨re une rÃ©ponse en fonction de ce contexte et de la question originale.

## Technologies UtilisÃ©es

- **Streamlit** : Interface utilisateur web
- **SentenceTransformers** : CrÃ©ation d'embeddings vectoriels
- **FAISS** : Index vectoriel pour la recherche de similaritÃ©
- **Pandas** : Manipulation des donnÃ©es
- **BeautifulSoup & Requests** : Extraction de donnÃ©es web
- **Ollama** : Interface pour les modÃ¨les de langage locaux
- **Mistral** : ModÃ¨le de gÃ©nÃ©ration de texte

## Auteurs

- [Hous20](https://github.com/Hous20)

## Licence

Ce projet est sous licence [LICENSE].